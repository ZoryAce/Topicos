{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZoryAce/Topicos/blob/main/Taller4_PretrainedModelsPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XMpXRys76MZ"
      },
      "source": [
        "# Tranfer Learnning to Flower Recognition using PyTorch \n",
        "This dataset contains labeled 4242 images of flowers.\n",
        "\n",
        "\n",
        "### Content\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.\n",
        "\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!\n",
        "\n",
        "## Data\n",
        "You can download data from: [Flowers Recognition Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePBa7UeC742g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "path=\"./\"\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5SpnEUuz-skn",
        "outputId": "4eb66185-c278-4a32-aef6-eee3ef458489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  flowers.zip\n",
            "replace flowers/daisy/10140303196_b88d3d6cec.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip flowers.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tzzG2nx-2sk"
      },
      "outputs": [],
      "source": [
        "path=\"./flowers\"\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frc4J-TT-z6c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQdfL32z_BWO"
      },
      "outputs": [],
      "source": [
        "classes=['dandelion', 'daisy', 'sunflower', 'tulip', 'rose']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VsLxwfHCbP5"
      },
      "outputs": [],
      "source": [
        "#CONTEO DE IMAGENES EN EL ARCHIVO LA CUAL DIFIERE DE LO INDICADO\n",
        "#EN EL ENCABEZADO (4317 IMAGENES)\n",
        "img_type = ('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')\n",
        "img_qty = sum([len(files) for r, d, files in os.walk(path)\n",
        "                   if any(file.lower().endswith(img_type) for file in files)])\n",
        "\n",
        "print(f\"N煤mero de imagenes: {img_qty}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Idt0FAef_FSL"
      },
      "outputs": [],
      "source": [
        "label_of_file=[]\n",
        "img_list=[]\n",
        "\n",
        "for kind in classes:\n",
        "    kind_parh=os.path.join(path,kind)\n",
        "\n",
        "    for img in os.listdir(kind_parh):\n",
        "        img_list.append(os.path.join(kind_parh,img))\n",
        "        label_of_file.append(kind)\n",
        "\n",
        "df=pd.DataFrame({'img':img_list,'label':label_of_file})\n",
        "df.head(3)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA7bAX2P_H1V"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "df['encode_label'] = encoder.fit_transform(df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6bm8oMo_Qd0"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okJJG8No_SgX"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNKSyejg_fpT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(example_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha9681z3_Zw9"
      },
      "outputs": [],
      "source": [
        "example_img = cv2.imread(df['img'][2])\n",
        "example_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlQpuDUz5L9V"
      },
      "outputs": [],
      "source": [
        "example_img_rgb = cv2.cvtColor(example_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(example_img_rgb)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVKrJowd_lUY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x=[]\n",
        "for img in df['img']:\n",
        "    try:\n",
        "        img = cv2.imread(img)\n",
        "        img = cv2.resize(img, (150, 150))\n",
        "        img = img / 255.0  # normalize\n",
        "        x.append(img)      # img\n",
        "\n",
        "    except:\n",
        "        print(f\"Error loading image: {img}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "064dSpPX_-qN"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6OpGOW28KSN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convertir a tensores x y y\n",
        "X_tensor = torch.tensor(np.array(x).transpose(0, 3, 1, 2), dtype=torch.float32)  # Formato (N, C, H, W)\n",
        "y_tensor = torch.tensor(df['encode_label'].values, dtype=torch.long)              # Etiquetas como tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtBEgxES_BnY"
      },
      "outputs": [],
      "source": [
        "df_tensor = TensorDataset(X_tensor, y_tensor)#crear dataset de tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB6_hpvnH3Cw"
      },
      "outputs": [],
      "source": [
        "#Creacion dataset entrenamiento y pruebas\n",
        "train_size = int(0.8 * len(df_tensor))\n",
        "test_size = len(df_tensor) - train_size\n",
        "train_dataset, test_dataset = random_split(df_tensor, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koa-V1B1AWj7"
      },
      "outputs": [],
      "source": [
        "# Creaci贸n de dataloader de entrenamiento y pruebas\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R09Z8ok_4nq"
      },
      "outputs": [],
      "source": [
        "# make model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_pGstGtA06r"
      },
      "outputs": [],
      "source": [
        "# train Model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzf8ppD-A4t9"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in zip(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      inputs = inputs.double()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      avg_loss = running_loss / len(train_loader.dataset)\n",
        "      print(f\"poca {epoch+1}/{num_epochs} - P茅rdida: {avg_loss:.4f}\")\n",
        "    print(\"Entrenamiento completado \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcau5NgTJJyJ"
      },
      "outputs": [],
      "source": [
        "# train model chat\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    # Iterate directly over the train_loader\n",
        "    for inputs, labels in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      #inputs = inputs.double()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      avg_loss = running_loss / len(train_loader.dataset)\n",
        "      print(f\"poca {epoch+1}/{num_epochs} - P茅rdida: {avg_loss:.4f}\")\n",
        "    print(\"Entrenamiento completado \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70QkOQoHCEND"
      },
      "outputs": [],
      "source": [
        "# Test Model\n",
        "def test_model(model):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in zip(test_loader):\n",
        "      # Permute the dimensions of the input tensor\n",
        "      inputs = inputs.permute(0, 3, 1, 2) # Change the order of dimensions from [batch_size, height, width, channels] to [batch_size, channels, height, width]\n",
        "      outputs = model(inputs)\n",
        "      test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
        "      pred = outputs.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "  test_loss /= len(X_train.dataset)\n",
        "  test_accuracy = 100. * correct / len(X_train.dataset)\n",
        "  print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(X_train.dataset)} ({test_accuracy:.0f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2HidwK2I1jn"
      },
      "outputs": [],
      "source": [
        "#chat\n",
        "def test_model(model, test_loader, criterion):\n",
        "    model.eval()  # Modo evaluaci贸n\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:  # Iteraci贸n correcta\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
        "\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)  # Predicci贸n m谩s probable\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'Test set: Average loss: {test_loss:.4f}, '\n",
        "          f'Accuracy: {correct}/{len(test_loader.dataset)} ({test_accuracy:.0f}%)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-1AUnkvAHGu"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjNNJgiFAMGh"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "train_model(model, criterion, optimizer, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqjMpz60APr-"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EftRkiiJx4KI"
      },
      "outputs": [],
      "source": [
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Desactiva el c谩lculo de gradientes\n",
        "    for images, labels in test_loader:\n",
        "        #images, labels = images.to(device), labels.to(device)  # GPU si est谩 disponible\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calcular la p茅rdida\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Calcular precisi贸n\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f'P茅rdida en test: {test_loss / len(test_loader):.4f}')\n",
        "print(f'Precisi贸n en test: {100 * correct / total:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}